{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#first\n",
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "from threading import Thread\n",
    "\n",
    "# Define MediaPipe object detection options\n",
    "BaseOptions = mp.tasks.BaseOptions\n",
    "ObjectDetector = mp.tasks.vision.ObjectDetector\n",
    "ObjectDetectorOptions = mp.tasks.vision.ObjectDetectorOptions\n",
    "VisionRunningMode = mp.tasks.vision.RunningMode\n",
    "\n",
    "options = ObjectDetectorOptions(\n",
    "    base_options=BaseOptions(model_asset_path='./model_384_int8.tflite'),  # Update this path\n",
    "    max_results=1,\n",
    "    running_mode=VisionRunningMode.IMAGE  # Frame-by-frame detection\n",
    ")\n",
    "detector = ObjectDetector.create_from_options(options)\n",
    "\n",
    "# Global variable to control video streaming\n",
    "running = True\n",
    "\n",
    "# Function to update the image widget with video frames\n",
    "def update_image_widget(image_widget):\n",
    "    global running\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video stream.\")\n",
    "        return\n",
    "\n",
    "    while running:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            continue\n",
    "\n",
    "        # Convert OpenCV image (BGR) to MediaPipe image (RGB)\n",
    "        mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "        # Perform object detection\n",
    "        detection_result = detector.detect(mp_image)\n",
    "\n",
    "        # Draw bounding boxes if detection results exist\n",
    "        for detection in detection_result.detections:\n",
    "            bbox = detection.bounding_box\n",
    "            start_point = (bbox.origin_x, bbox.origin_y)\n",
    "            end_point = (bbox.origin_x + bbox.width, bbox.origin_y + bbox.height)\n",
    "            cv2.rectangle(frame, start_point, end_point, (0, 0, 255), 2)\n",
    "\n",
    "            # Draw label and score\n",
    "            category = detection.categories[0]\n",
    "            category_name = category.category_name\n",
    "            probability = round(category.score, 2)\n",
    "            result_text = f\"{category_name} ({probability})\"\n",
    "            text_location = (bbox.origin_x + 10, bbox.origin_y + 20)\n",
    "            cv2.putText(frame, result_text, text_location, cv2.FONT_HERSHEY_PLAIN, 1, (0, 0, 255), 1)\n",
    "\n",
    "        # Convert frame to JPEG format\n",
    "        _, frame_jpeg = cv2.imencode('.jpeg', frame)\n",
    "\n",
    "        # Update image widget\n",
    "        image_widget.value = frame_jpeg.tobytes()\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "# Function to stop the video capture loop\n",
    "def stop_camera(button):\n",
    "    global running\n",
    "    running = False\n",
    "    stop_button.disabled = True  # Disable the stop button once clicked\n",
    "\n",
    "# Create an Image widget to display video frames\n",
    "image_widget = widgets.Image(format='jpeg', width=640, height=480)\n",
    "\n",
    "# Create a Button widget to stop the video capture\n",
    "stop_button = widgets.Button(description=\"Stop Camera\")\n",
    "stop_button.on_click(stop_camera)\n",
    "\n",
    "# Display the image widget and stop button\n",
    "display(image_widget, stop_button)\n",
    "\n",
    "# Start a thread to update the image widget with video frames\n",
    "thread = Thread(target=update_image_widget, args=(image_widget,))\n",
    "thread.start()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
